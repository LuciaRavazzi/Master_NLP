{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXo6F_5OF4gU"
   },
   "source": [
    "### CLASSIFICAZIONE PURA\n",
    "\n",
    "Lo scopo di questo lavoro Ã¨ quello di classificare alcune recensioni Amazon attraverso metodi tradizionali di machine learning. \n",
    "In particolare, le rappresentazioni utilizzate sono BOW con pesi binari, frequenze e tf-idf ed un vocabolario costituito da 2-gram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3buo9VLXnzU5",
    "outputId": "76fdf8e2-533c-40c5-9620-7abf0deabf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6PoucXYhfOB",
    "outputId": "c2f68bf6-49ff-49ff-9d9d-d845f1d115c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n_hfnkwn3za",
    "outputId": "17e679cc-6efa-4732-c861-553ce09b2884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Collecting demoji\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/fd/265f1ad2d745d6f46d1ede83d0054327e87154e9f14b252c1e272749e657/demoji-0.3.0-py2.py3-none-any.whl\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
      "Installing collected packages: colorama, demoji\n",
      "Successfully installed colorama-0.4.4 demoji-0.3.0\n",
      "Downloading emoji data ...\n",
      "... OK (Got response in 1.41 seconds)\n",
      "Writing emoji data to /root/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "# Plot.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP pipeline.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words = stop_words + ['would'] + ['-PRON-'] # -PRON- viene aggiunto dal lemmatizer e va tolto.\n",
    "import spacy # lemmatization\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "!pip install demoji\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "\n",
    "# Rappresentazione.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Classificatori.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cLI1dRKMCJ2W"
   },
   "outputs": [],
   "source": [
    "# Codifica le sigle nei rispettivi classificatori. \n",
    "def decode(c):\n",
    "  decoder = {'KNN': 'KNN', \n",
    "             'LSVC': 'Linear SVC', \n",
    "             'Logistic': 'Logistic', \n",
    "             'GNB': 'Gaussian Naive Bayes', \n",
    "             'Tree': 'Decision Tree Classifier', \n",
    "             'RF': 'Random Forest',\n",
    "             'SGD':'Stochastic Gradient Descent Classifier',\n",
    "             'MNB': 'Multinomial Naive Bayes', \n",
    "             'ADAB': 'Adaboost',\n",
    "             'BNB': 'Bernullian Naive Bayes'}\n",
    "  return decoder[c] \n",
    "\n",
    "\n",
    "# NLP pipeline.\n",
    "\n",
    "def pipe(doc):\n",
    "  doc = doc.lower()   # Lower case. \n",
    "  doc = re.sub(r'\\d+', ' ', doc)  # Drop digits.\n",
    "  doc = re.sub('['+string.punctuation+']', ' ', doc) # Drop punctuation. \n",
    "  doc = re.sub(r'\\n+', ' ', doc) # Drop newline.\n",
    "  if 'www.' in doc or 'http:' in doc or 'https:' in doc or '.com' in doc: # Drop URL.\n",
    "    doc = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", doc)\n",
    "  doc = demoji.replace(string = doc, repl = \" \")  # Drop emoji.\n",
    "  doc = re.sub(r'\\s\\s+', ' ', doc) # Drop extra spaces. \n",
    "  doc = nlp(doc)  \n",
    "  doc = [token.lemma_ for token in doc]  # Tokenize and Lemmatization. \n",
    "  doc = [word for word in doc if len(word) > 2] # Drop short words.\n",
    "  doc = [word for word in doc if word not in stop_words] # Drop stop words.\n",
    "  return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NUGiH6Ch1w_0"
   },
   "outputs": [],
   "source": [
    "# NLP pipeline: load, sample, clean dataset.\n",
    "\n",
    "class preprocessing:\n",
    "  # Initialize.\n",
    "  def __init__(self, path, name_df):\n",
    "    self.path = path\n",
    "    self.name_df = name_df\n",
    "\n",
    "  # Load data.\n",
    "  def loader(self):\n",
    "    print('IMPORT DATASET ' + self.name_df)\n",
    "    if os.path.isfile(self.path) == False: \n",
    "      print('Set not exists.')\n",
    "      raise SystemExit(\"Stop right there!\")\n",
    "    else:\n",
    "      with open(self.path, encoding=\"utf8\") as file:\n",
    "       self.df = file.readlines()\n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    " # Sampling.\n",
    "  def sampling(self, size):\n",
    "    print('SAMPLING ' + self.name_df)\n",
    "    random.seed = 20201230\n",
    "    self.df = random.sample(self.df, size)  \n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    "  # From list to data frame\n",
    "  def data_frame(self):\n",
    "    print('CREATE DATASET: REVIEWS - LABELS ' + self.name_df)\n",
    "    X = []\n",
    "    labels = []\n",
    "\n",
    "    for rev in self.df:\n",
    "      _, label, sent = re.split(r'__label__(\\d)', rev)\n",
    "      label = int(label[0]) - 1\n",
    "      labels.append(label)\n",
    "      X.append(sent)\n",
    "\n",
    "    self.df = pd.DataFrame(list(zip(X, labels)), columns=['Review', 'Labels']) \n",
    "\n",
    "  # NLP pipeline.\n",
    "  def pipeline(self):\n",
    "    print('NLP pipeline ' + self.name_df)\n",
    "    t1 = time()\n",
    "    self.df[\"Clean_Review\"] = self.df[\"Review\"].apply(pipe)\n",
    "    t2 = time()\n",
    "    print(f\"Time: {t2-t1}\")\n",
    "\n",
    "  # Empty review,\n",
    "  def drop_empty_review(self):\n",
    "    print('DROP EMPTY REVIEW ' + self.name_df)\n",
    "    self.df.drop(self.df[self.df['Clean_Review'].map(len) == 0].index)\n",
    "\n",
    "# Set of possible classification techniques.\n",
    "class classification:\n",
    "    # Initialize.\n",
    "    def __init__(self, X_train, y_train, cv):\n",
    "        self.seed = 20201230\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.cv = cv\n",
    "\n",
    "    # Select the model.\n",
    "    def select_model(self, class_type):\n",
    "      possible_class = ['KNN', 'LSVC', 'Logistic', 'Tree', 'RF', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "      if class_type in possible_class:\n",
    "        if class_type == possible_class[0]:\n",
    "          clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "        if class_type == possible_class[1]:\n",
    "          clf = LinearSVC(random_state=0, max_iter=1000)\n",
    "        if class_type == possible_class[2]:\n",
    "          clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "        if class_type == possible_class[3]:\n",
    "          clf = DecisionTreeClassifier()\n",
    "        if class_type == possible_class[4]:\n",
    "          clf = RandomForestClassifier()\n",
    "        if class_type == possible_class[5]:\n",
    "          clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "        if class_type == possible_class[6]:\n",
    "          clf = MultinomialNB()\n",
    "        if class_type == possible_class[7]:\n",
    "          clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "        if class_type == possible_class[8]:\n",
    "          clf = BernoulliNB()\n",
    "\n",
    "        self.clf = clf\n",
    "        # Cross validation.\n",
    "        self.score = cross_validate(self.clf, self.X_train, self.y_train, cv=self.cv, scoring = ['accuracy', 'f1'])\n",
    "        self.N = int(self.X_train.shape[0]/cv)\n",
    "        # Performance.\n",
    "        perf = []\n",
    "        for key in self.score:          \n",
    "          perf.append([key, self.score[key].mean(), self.score[key].std() * 2/np.sqrt(self.N)])\n",
    "\n",
    "        perf = np.array(perf)\n",
    "        perf =  pd.DataFrame(perf, columns = ['Measure', 'Mean', 'StandError'])\n",
    "        perf['Measure'] = ['TrainTime', 'TestTime', 'F1', 'Accuracy']\n",
    "        print(perf)\n",
    "        self.perf = perf\n",
    "      else:\n",
    "        raise SystemExit(\"Select one of the provided classifiers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIKI0kBVx960"
   },
   "source": [
    "### ***IMPORT AND PREPROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhtnq7HBBskd",
    "outputId": "8c757c49-b872-4aee-984d-1ebfc8ec7764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT DATASET TRAIN\n",
      "Size: 3600000\n",
      "SAMPLING TRAIN\n",
      "Size: 250000\n",
      "CREATE DATASET: REVIEWS - LABELS TRAIN\n",
      "NLP pipeline TRAIN\n",
      "Time: 1982.5033721923828\n",
      "DROP EMPTY REVIEW TRAIN\n",
      "CPU times: user 33min 3s, sys: 6.36 s, total: 33min 9s\n",
      "Wall time: 33min 30s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "\n",
    "        #-- IMPORT SET.\n",
    "\n",
    "train_path = 'drive/MyDrive/Text Mining/train.ft.txt'\n",
    "\n",
    "train = preprocessing(train_path, 'TRAIN')\n",
    "\n",
    "train.loader()\n",
    "\n",
    "      #-- SAMPLING.\n",
    "\n",
    "train_sample_size = 250000\n",
    "train.sampling(train_sample_size)\n",
    "\n",
    "      #-- CREATE A DATASET WITH REVIEW - LABEL.\n",
    "\n",
    "train.data_frame()\n",
    "\n",
    "      #-- PREPROCESSING.\n",
    "\n",
    "train.pipeline()\n",
    "\n",
    "      #-- DROP EMPTY REVIEWS.\n",
    "\n",
    "train.drop_empty_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IElCkQuPyDFR"
   },
   "source": [
    "### ***FEATURE EXTRACTION - SELECTION - WEIGHTED***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QuhIXoqsw4g4"
   },
   "outputs": [],
   "source": [
    "# Number of min and max gram.\n",
    "gram_min = 2\n",
    "gram_max = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMRUkukz8zyJ"
   },
   "source": [
    "#### ***BINARY MATRIX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpMlzKqWzT-n",
    "outputId": "81ad12f8-f56e-4adc-bf2c-d2202510ef3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 35539)\n",
      "(250000, 3553)\n",
      "CPU times: user 39.5 s, sys: 805 ms, total: 40.3 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- FEATURE EXTRACTION: BINARY BOW.\n",
    "\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.0001*100000 = 10, ragionevole\n",
    "        # max_df = 0.8, # stop words removal: it's useless if I had removed stop words!\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = True\n",
    "    )  \n",
    "\n",
    "train_BOW = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_BOW.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile = 10)\n",
    "train_BOW = select_percentile.fit_transform(train_BOW, train.df['Labels'])\n",
    "\n",
    "print(train_BOW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IUy3jFQyORt"
   },
   "source": [
    "##### ***CLASSIFICATION***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktRzl4gUn6Y-",
    "outputId": "a60f65e8-992e-4ca7-b08f-88ff897f6660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime  0.029909420013427734    3.48113532821378e-05\n",
      "1   TestTime    187.78434057235717     0.06976580160524748\n",
      "2         F1    0.7256199999999999  1.8177788644387045e-05\n",
      "3   Accuracy    0.7371862454360342  0.00012463130498352245\n",
      "                                                            ***** Linear SVC ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime    10.362391471862793    0.004675259326221499\n",
      "1   TestTime  0.028976631164550782  2.3834370009457774e-06\n",
      "2         F1              0.814432   5.028685712987151e-06\n",
      "3   Accuracy    0.8268141109264825  6.9776989458652035e-06\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime     4.690478324890137    0.002310207422521882\n",
      "1   TestTime  0.028639793395996094  3.1327035670318446e-06\n",
      "2         F1    0.8142159999999998   6.848672864139316e-06\n",
      "3   Accuracy    0.8141883847481433   9.252766862970524e-05\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                  Mean             StandError\n",
      "0  TrainTime   0.40723958015441897  0.0002134149566519521\n",
      "1   TestTime  0.028870010375976564  4.902674763668112e-06\n",
      "2         F1              0.808276  8.535216458883792e-06\n",
      "3   Accuracy     0.821463023097615  9.220105564708482e-06\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.05252299308776855    9.58977114723147e-06\n",
      "1   TestTime  0.030090188980102538   8.202285139092017e-06\n",
      "2         F1    0.8111200000000001  1.0072378070743689e-05\n",
      "3   Accuracy    0.8240251955213159   9.061020370590484e-06\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean             StandError\n",
      "0  TrainTime  10.315010213851929  0.0022336257176721577\n",
      "1   TestTime  0.7772564888000488  8.823453211972239e-05\n",
      "2         F1              0.6471  7.014499269370465e-06\n",
      "3   Accuracy  0.7295722374773852  5.123608550588082e-06\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime  0.06035394668579101  3.4367713652132825e-06\n",
      "1   TestTime   0.0326960563659668  3.7793646065239016e-06\n",
      "2         F1             0.811068  1.1492522786577223e-05\n",
      "3   Accuracy   0.8242500378824242  1.0139786763078209e-05\n",
      "CPU times: user 17min 48s, sys: 4.73 s, total: 17min 53s\n",
      "Wall time: 17min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = 5\n",
    "learn = classification(train_BOW, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)\n",
    "\n",
    "# del train_BOW, test_BOW, learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6195UAxLIiX7"
   },
   "source": [
    "#### ***FREQUENCY MATRIX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XCRF-iDIh2C",
    "outputId": "0c7f43c6-1759-44e7-80d5-f366bac0e198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 35539)\n",
      "(250000, 3553)\n",
      "CPU times: user 37.3 s, sys: 780 ms, total: 38.1 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- FEATURE EXTRACTION: FREQUENCY BOW.\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.001*100000 = 100, ragionevole\n",
    "        # max_df = 0.7,\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = False, \n",
    "        # vocabulary = my_dic\n",
    "    )  \n",
    "\n",
    "# Restituisce un amatrice di TIPO sparso quindi non bisogna convertirla. \n",
    "train_freq = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_freq.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile=10)\n",
    "train_freq = select_percentile.fit_transform(train_freq, train.df['Labels'])\n",
    "\n",
    "print(train_freq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQNrZQ3ZsPod"
   },
   "source": [
    "##### ***CLASSIFICATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8fO1NU9r0Zr",
    "outputId": "f6407308-a6e7-43ba-abd3-dfca034e213f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime  0.03053746223449707  3.8089382893811635e-05\n",
      "1   TestTime   191.47071652412416     0.02031208658878715\n",
      "2         F1   0.7251879999999999  1.4998069209068289e-05\n",
      "3   Accuracy   0.7366409616866082  0.00011507305517374916\n",
      "                                                            ***** Linear SVC ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Measure                 Mean             StandError\n",
      "0  TrainTime    32.27579636573792    0.01120961817550929\n",
      "1   TestTime  0.02977900505065918  5.902192017424547e-06\n",
      "2         F1   0.8149040000000001  7.046724061576457e-06\n",
      "3   Accuracy   0.8272321324320162   8.82861213659801e-06\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime    4.785932731628418    0.004766517368205458\n",
      "1   TestTime  0.02878575325012207    2.81966110114813e-06\n",
      "2         F1             0.814508  1.0005182657003084e-05\n",
      "3   Accuracy   0.8265989989243634  1.1170386732967066e-05\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime  0.4791764736175537  0.00026696413261475285\n",
      "1   TestTime  0.0292604923248291   5.231326128745559e-06\n",
      "2         F1            0.809484   1.098385724597691e-05\n",
      "3   Accuracy  0.8224678785199304  1.2014523480740615e-05\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime  0.05539336204528809  1.0019962329722374e-05\n",
      "1   TestTime  0.03115253448486328   3.847150419526006e-06\n",
      "2         F1   0.8113800000000001    1.16772599525745e-05\n",
      "3   Accuracy   0.8241625960228633   1.137022104866392e-05\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime   11.09772801399231    0.003563677408706515\n",
      "1   TestTime  0.8054419994354248  0.00019843695395400669\n",
      "2         F1              0.6471   7.014499269370465e-06\n",
      "3   Accuracy  0.7295722374773852   5.123608550588082e-06\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime  0.06347756385803223   8.121171804387173e-06\n",
      "1   TestTime  0.03401417732238769  7.0046616245637756e-06\n",
      "2         F1   0.8113239999999999   1.278519143384264e-05\n",
      "3   Accuracy    0.824288121776485  1.1397347509327696e-05\n",
      "CPU times: user 20min 1s, sys: 4.21 s, total: 20min 5s\n",
      "Wall time: 20min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = classification(train_freq, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ajMrbVvKU3-"
   },
   "source": [
    "#### ***TF-IDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg3zlcx0Zrwf",
    "outputId": "be59cb02-77ff-4e2b-cb13-7044ef182861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 35539)\n",
      "(250000, 3554)\n",
      "CPU times: user 38.8 s, sys: 858 ms, total: 39.6 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- TF-IDF\n",
    "\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.001*100000 = 100, ragionevole\n",
    "        # max_df = 0.7,\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = False,\n",
    "        # vocabulary = my_dic\n",
    "    )  \n",
    "\n",
    "train_tf_idf = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_tf_idf.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile=10)\n",
    "train_tf_idf = select_percentile.fit_transform(train_tf_idf, train.df['Labels'])\n",
    "\n",
    "print(train_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***CLASSIFICATION***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uiwrjLyJ00S",
    "outputId": "9b6927b5-bdc4-4b2d-89d8-f5b15f7d11e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime  0.030478382110595705   4.738568745019273e-06\n",
      "1   TestTime    195.24522523880006     0.02123646129729317\n",
      "2         F1              0.755972  1.7249083453911367e-05\n",
      "3   Accuracy     0.754446958254523  0.00012296331113154975\n",
      "                                                            ***** Linear SVC ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime     1.965989637374878  0.00024523441824141903\n",
      "1   TestTime  0.029101991653442384   8.236781509753625e-06\n",
      "2         F1    0.8185439999999999  1.9718466471812684e-05\n",
      "3   Accuracy    0.8105136682317232   2.370114760514954e-05\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime    3.4239308834075928    0.009269846231382084\n",
      "1   TestTime  0.028853225708007812   5.715673299536257e-06\n",
      "2         F1              0.814332  1.9865338658074576e-05\n",
      "3   Accuracy    0.8062043786285255  2.3452091522396786e-05\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.35388994216918945  0.00014902772759533997\n",
      "1   TestTime  0.029396724700927735  1.0010933789701578e-05\n",
      "2         F1              0.800848  2.0768468407660832e-05\n",
      "3   Accuracy    0.7925705961419809  2.4732057466883916e-05\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.05473947525024414   5.304157880937872e-06\n",
      "1   TestTime  0.031497859954833986  1.1821450441774335e-05\n",
      "2         F1    0.8124039999999999  1.3411111810733546e-05\n",
      "3   Accuracy    0.8265340447087487  1.1150627714677163e-05\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime   17.76159300804138   0.0007811522397242304\n",
      "1   TestTime  0.7828579425811768   4.944277110035079e-05\n",
      "2         F1  0.6457080000000001  1.0012216537810072e-05\n",
      "3   Accuracy  0.7289534356757948  4.5498327205520725e-06\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime  0.061517858505249025   3.796591850929971e-06\n",
      "1   TestTime    0.0327664852142334   4.108928917417675e-06\n",
      "2         F1              0.811896   1.315283695633769e-05\n",
      "3   Accuracy    0.8262652962924453  1.1038662791129763e-05\n",
      "CPU times: user 18min 14s, sys: 4.19 s, total: 18min 18s\n",
      "Wall time: 18min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = classification(train_tf_idf, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SpJpgkSJznf7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IWxk6bVxVomb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Classificazione(2,2)CVMore.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
