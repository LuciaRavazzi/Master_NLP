{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXo6F_5OF4gU"
   },
   "source": [
    "### CLASSIFICAZIONE PURA\n",
    "\n",
    "Lo scopo di questo lavoro Ã¨ quello di classificare alcune recensioni Amazon attraverso metodi tradizionali di machine learning. \n",
    "In particolare, le rappresentazioni utilizzate sono BOW con pesi binari, frequenze e tf-idf ed un vocabolario costituito da 1-gram e 2-gram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3buo9VLXnzU5",
    "outputId": "76fdf8e2-533c-40c5-9620-7abf0deabf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6PoucXYhfOB",
    "outputId": "c2f68bf6-49ff-49ff-9d9d-d845f1d115c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n_hfnkwn3za",
    "outputId": "17e679cc-6efa-4732-c861-553ce09b2884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Collecting demoji\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/fd/265f1ad2d745d6f46d1ede83d0054327e87154e9f14b252c1e272749e657/demoji-0.3.0-py2.py3-none-any.whl\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
      "Installing collected packages: colorama, demoji\n",
      "Successfully installed colorama-0.4.4 demoji-0.3.0\n",
      "Downloading emoji data ...\n",
      "... OK (Got response in 1.41 seconds)\n",
      "Writing emoji data to /root/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "# Plot.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP pipeline.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words = stop_words + ['would'] + ['-PRON-'] # -PRON- viene aggiunto dal lemmatizer e va tolto.\n",
    "import spacy # lemmatization\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "!pip install demoji\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "\n",
    "# Rappresentazione.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# Classificatori.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cLI1dRKMCJ2W"
   },
   "outputs": [],
   "source": [
    "# Codifica le sigle nei rispettivi classificatori. \n",
    "def decode(c):\n",
    "  decoder = {'KNN': 'KNN', \n",
    "             'LSVC': 'Linear SVC', \n",
    "             'Logistic': 'Logistic', \n",
    "             'GNB': 'Gaussian Naive Bayes', \n",
    "             'Tree': 'Decision Tree Classifier', \n",
    "             'RF': 'Random Forest',\n",
    "             'SGD':'Stochastic Gradient Descent Classifier',\n",
    "             'MNB': 'Multinomial Naive Bayes', \n",
    "             'ADAB': 'Adaboost',\n",
    "             'BNB': 'Bernullian Naive Bayes'}\n",
    "  return decoder[c] \n",
    "\n",
    "\n",
    "# NLP pipeline.\n",
    "\n",
    "def pipe(doc):\n",
    "  doc = doc.lower()   # Lower case. \n",
    "  doc = re.sub(r'\\d+', ' ', doc)  # Drop digits.\n",
    "  doc = re.sub('['+string.punctuation+']', ' ', doc) # Drop punctuation. \n",
    "  doc = re.sub(r'\\n+', ' ', doc) # Drop newline.\n",
    "  if 'www.' in doc or 'http:' in doc or 'https:' in doc or '.com' in doc: # Drop URL.\n",
    "    doc = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", doc)\n",
    "  doc = demoji.replace(string = doc, repl = \" \")  # Drop emoji.\n",
    "  doc = re.sub(r'\\s\\s+', ' ', doc) # Drop extra spaces. \n",
    "  doc = nlp(doc)  \n",
    "  doc = [token.lemma_ for token in doc]  # Tokenize and Lemmatization. \n",
    "  doc = [word for word in doc if len(word) > 2] # Drop short words.\n",
    "  doc = [word for word in doc if word not in stop_words] # Drop stop words.\n",
    "  return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NUGiH6Ch1w_0"
   },
   "outputs": [],
   "source": [
    "# NLP pipeline: load, sample, clean dataset.\n",
    "\n",
    "class preprocessing:\n",
    "  # Initialize.\n",
    "  def __init__(self, path, name_df):\n",
    "    self.path = path\n",
    "    self.name_df = name_df\n",
    "\n",
    "  # Load data.\n",
    "  def loader(self):\n",
    "    print('IMPORT DATASET ' + self.name_df)\n",
    "    if os.path.isfile(self.path) == False: \n",
    "      print('Set not exists.')\n",
    "      raise SystemExit(\"Stop right there!\")\n",
    "    else:\n",
    "      with open(self.path, encoding=\"utf8\") as file:\n",
    "       self.df = file.readlines()\n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    " # Sampling.\n",
    "  def sampling(self, size):\n",
    "    print('SAMPLING ' + self.name_df)\n",
    "    random.seed = 20201230\n",
    "    self.df = random.sample(self.df, size)  \n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    "  # From list to data frame\n",
    "  def data_frame(self):\n",
    "    print('CREATE DATASET: REVIEWS - LABELS ' + self.name_df)\n",
    "    X = []\n",
    "    labels = []\n",
    "\n",
    "    for rev in self.df:\n",
    "      _, label, sent = re.split(r'__label__(\\d)', rev)\n",
    "      label = int(label[0]) - 1\n",
    "      labels.append(label)\n",
    "      X.append(sent)\n",
    "\n",
    "    self.df = pd.DataFrame(list(zip(X, labels)), columns=['Review', 'Labels']) \n",
    "\n",
    "  # NLP pipeline.\n",
    "  def pipeline(self):\n",
    "    print('NLP pipeline ' + self.name_df)\n",
    "    t1 = time()\n",
    "    self.df[\"Clean_Review\"] = self.df[\"Review\"].apply(pipe)\n",
    "    t2 = time()\n",
    "    print(f\"Time: {t2-t1}\")\n",
    "\n",
    "  # Empty review,\n",
    "  def drop_empty_review(self):\n",
    "    print('DROP EMPTY REVIEW ' + self.name_df)\n",
    "    self.df.drop(self.df[self.df['Clean_Review'].map(len) == 0].index)\n",
    "\n",
    "# Set of possible classification techniques.\n",
    "class classification:\n",
    "    # Initialize.\n",
    "    def __init__(self, X_train, y_train, cv):\n",
    "        self.seed = 20201230\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.cv = cv\n",
    "\n",
    "    # Select the model.\n",
    "    def select_model(self, class_type):\n",
    "      possible_class = ['KNN', 'LSVC', 'Logistic', 'Tree', 'RF', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "      if class_type in possible_class:\n",
    "        if class_type == possible_class[0]:\n",
    "          clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "        if class_type == possible_class[1]:\n",
    "          clf = LinearSVC(random_state=0, max_iter=1000)\n",
    "        if class_type == possible_class[2]:\n",
    "          clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "        if class_type == possible_class[3]:\n",
    "          clf = DecisionTreeClassifier()\n",
    "        if class_type == possible_class[4]:\n",
    "          clf = RandomForestClassifier()\n",
    "        if class_type == possible_class[5]:\n",
    "          clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "        if class_type == possible_class[6]:\n",
    "          clf = MultinomialNB()\n",
    "        if class_type == possible_class[7]:\n",
    "          clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "        if class_type == possible_class[8]:\n",
    "          clf = BernoulliNB()\n",
    "\n",
    "        self.clf = clf\n",
    "        # Cross validation.\n",
    "        self.score = cross_validate(self.clf, self.X_train, self.y_train, cv=self.cv, scoring = ['accuracy', 'f1'])\n",
    "        self.N = int(self.X_train.shape[0]/cv)\n",
    "        # Performances.\n",
    "        perf = []\n",
    "        for key in self.score:          \n",
    "          perf.append([key, self.score[key].mean(), self.score[key].std() * 2/np.sqrt(self.N)])\n",
    "\n",
    "        perf = np.array(perf)\n",
    "        perf =  pd.DataFrame(perf, columns = ['Measure', 'Mean', 'StandError'])\n",
    "        perf['Measure'] = ['TrainTime', 'TestTime', 'F1', 'Accuracy']\n",
    "        print(perf)\n",
    "        self.perf = perf\n",
    "      else:\n",
    "        raise SystemExit(\"Select one of the provided classifiers!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIKI0kBVx960"
   },
   "source": [
    "### ***IMPORT AND PREPROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhtnq7HBBskd",
    "outputId": "8c757c49-b872-4aee-984d-1ebfc8ec7764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT DATASET TRAIN\n",
      "Size: 3600000\n",
      "SAMPLING TRAIN\n",
      "Size: 250000\n",
      "CREATE DATASET: REVIEWS - LABELS TRAIN\n",
      "NLP pipeline TRAIN\n",
      "Time: 1982.5033721923828\n",
      "DROP EMPTY REVIEW TRAIN\n",
      "CPU times: user 33min 3s, sys: 6.36 s, total: 33min 9s\n",
      "Wall time: 33min 30s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "\n",
    "        #-- IMPORT SET.\n",
    "\n",
    "train_path = 'drive/MyDrive/Text Mining/train.ft.txt'\n",
    "\n",
    "train = preprocessing(train_path, 'TRAIN')\n",
    "\n",
    "train.loader()\n",
    "\n",
    "      #-- SAMPLING.\n",
    "\n",
    "train_sample_size = 250000\n",
    "train.sampling(train_sample_size)\n",
    "\n",
    "      #-- CREATE A DATASET WITH REVIEW - LABEL.\n",
    "\n",
    "train.data_frame()\n",
    "\n",
    "      #-- PREPROCESSING.\n",
    "\n",
    "train.pipeline()\n",
    "\n",
    "      #-- DROP EMPTY REVIEWS.\n",
    "\n",
    "train.drop_empty_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IElCkQuPyDFR"
   },
   "source": [
    "### ***FEATURE EXTRACTION - SELECTION - WEIGHTED***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QuhIXoqsw4g4"
   },
   "outputs": [],
   "source": [
    "# Number of min and max gram.\n",
    "gram_min = 1\n",
    "gram_max = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMRUkukz8zyJ"
   },
   "source": [
    "#### ***BINARY MATRIX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpMlzKqWzT-n",
    "outputId": "b8d07351-7d45-42ff-f5d9-6ae38bb98e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 49651)\n",
      "(250000, 4965)\n",
      "CPU times: user 41.8 s, sys: 1.55 s, total: 43.4 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- FEATURE EXTRACTION: BINARY BOW.\n",
    "\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.0001*100000 = 10, ragionevole\n",
    "        # max_df = 0.8, # stop words removal: it's useless if I had removed stop words!\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = True\n",
    "    )  \n",
    "\n",
    "train_BOW = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_BOW.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile = 10)\n",
    "train_BOW = select_percentile.fit_transform(train_BOW, train.df['Labels'])\n",
    "\n",
    "print(train_BOW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IUy3jFQyORt"
   },
   "source": [
    "##### ***CLASSIFICATION***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktRzl4gUn6Y-",
    "outputId": "231da402-b325-400a-d15e-33d8ac60e0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime  0.056425857543945315   2.753943982440745e-05\n",
      "1   TestTime      405.426735830307    0.028792811364903085\n",
      "2         F1              0.693416  1.6904967317330087e-05\n",
      "3   Accuracy    0.7055746159637808  1.4800327564727049e-05\n",
      "                                                            ***** Linear SVC ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Measure                 Mean              StandError\n",
      "0  TrainTime    47.31369495391846   0.0022346984335219968\n",
      "1   TestTime  0.03417601585388184   2.692033779321446e-06\n",
      "2         F1             0.892408  1.5533849490708952e-05\n",
      "3   Accuracy   0.8933637621278171  1.5140168834118887e-05\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime    12.047234106063843    0.002817145313543353\n",
      "1   TestTime  0.033413267135620116   7.134668690415614e-06\n",
      "2         F1              0.892984  1.2695775675397014e-05\n",
      "3   Accuracy    0.8937880497236119  1.2310704634865834e-05\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime   1.1151763439178466    0.000486505579879718\n",
      "1   TestTime  0.03344082832336426   4.446155058648363e-06\n",
      "2         F1             0.889756  1.5225830683414215e-05\n",
      "3   Accuracy    0.890818120279173  1.5002947648326382e-05\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime    0.0841519832611084  1.1962013324979427e-05\n",
      "1   TestTime  0.036791229248046876  3.1768975981109393e-06\n",
      "2         F1    0.8710759999999999  1.0035712231824944e-05\n",
      "3   Accuracy    0.8725046724452767   9.499866565725646e-06\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime    30.3966335773468    0.003439034367422685\n",
      "1   TestTime   1.574930238723755  0.00011789760126604169\n",
      "2         F1             0.82026  2.1276992268645445e-05\n",
      "3   Accuracy  0.8217304627048488  2.3828734036342468e-05\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                 Mean             StandError\n",
      "0  TrainTime  0.12036547660827637  1.232802336470496e-05\n",
      "1   TestTime  0.05018906593322754  6.533864517538166e-06\n",
      "2         F1             0.864344  9.588259487518995e-06\n",
      "3   Accuracy   0.8682924708090075  8.592573795031468e-06\n",
      "CPU times: user 41min 15s, sys: 15 s, total: 41min 30s\n",
      "Wall time: 41min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = 5\n",
    "learn = classification(train_BOW, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)\n",
    "\n",
    "# del train_BOW, test_BOW, learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6195UAxLIiX7"
   },
   "source": [
    "#### ***FREQUENCY MATRIX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XCRF-iDIh2C",
    "outputId": "fcf11386-ea0c-475f-9dc4-c1440ce4f3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 49651)\n",
      "(250000, 4965)\n",
      "CPU times: user 43.3 s, sys: 931 ms, total: 44.3 s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- FEATURE EXTRACTION: FREQUENCY BOW.\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.001*100000 = 100, ragionevole\n",
    "        # max_df = 0.7,\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = False,\n",
    "        # vocabulary = my_dic\n",
    "    )  \n",
    "\n",
    "# Restituisce un amatrice di TIPO sparso quindi non bisogna convertirla. \n",
    "train_freq = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_freq.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile=10)\n",
    "train_freq = select_percentile.fit_transform(train_freq, train.df['Labels'])\n",
    "\n",
    "print(train_freq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQNrZQ3ZsPod"
   },
   "source": [
    "##### ***CLASSIFICATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8fO1NU9r0Zr",
    "outputId": "d246d6e6-8999-42bc-8558-324a7402088f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime  0.051820564270019534  3.0159343966696418e-05\n",
      "1   TestTime    424.34550976753235    0.031770297823593995\n",
      "2         F1              0.695364   1.644322109563688e-05\n",
      "3   Accuracy     0.712854534764533   1.136842365313508e-05\n",
      "                                                            ***** Linear SVC ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Measure                  Mean              StandError\n",
      "0  TrainTime     49.95259823799133     0.00764890861470465\n",
      "1   TestTime  0.032660055160522464  5.7941280929614035e-06\n",
      "2         F1               0.89284  1.0676328957090177e-05\n",
      "3   Accuracy    0.8938462416191297  1.0532332214564921e-05\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime    16.73496298789978    0.009529439249489648\n",
      "1   TestTime  0.03167815208435058  3.2032122764567216e-06\n",
      "2         F1               0.8939  1.0141400297789258e-05\n",
      "3   Accuracy   0.8947499851691157   9.939340412747645e-06\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime   1.2920207500457763   0.0005322219477875733\n",
      "1   TestTime  0.03147468566894531  3.3296540341082516e-06\n",
      "2         F1             0.890184  5.5175646801828805e-06\n",
      "3   Accuracy   0.8909342015334222    6.05934079441549e-06\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.08293991088867188  1.2129632236721518e-05\n",
      "1   TestTime  0.035569286346435545   7.881038485660794e-06\n",
      "2         F1    0.8644320000000001  1.1244824587337865e-05\n",
      "3   Accuracy    0.8659294390834283   9.603406924250087e-06\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime   32.95146112442016   0.0022919228525582857\n",
      "1   TestTime       1.37099609375   9.032912634877854e-05\n",
      "2         F1  0.8217679999999999  1.5450814865242735e-05\n",
      "3   Accuracy  0.8212631697228424   1.676573534619777e-05\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.12082061767578126  1.6652688363163267e-05\n",
      "1   TestTime  0.048255634307861325   1.490847781188826e-05\n",
      "2         F1    0.8625200000000002    9.07850207908773e-06\n",
      "3   Accuracy    0.8665122430073655   7.936379143073526e-06\n",
      "CPU times: user 43min 45s, sys: 8.66 s, total: 43min 54s\n",
      "Wall time: 43min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = classification(train_freq, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ajMrbVvKU3-"
   },
   "source": [
    "#### ***TF-IDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg3zlcx0Zrwf",
    "outputId": "24f377fa-9b97-4633-c1f2-4bfcaf65f1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 49651)\n",
      "(250000, 4965)\n",
      "CPU times: user 43.6 s, sys: 844 ms, total: 44.5 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "    #-- TF-IDF\n",
    "\n",
    "def dummy(doc):\n",
    "  return doc\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        min_df = 0.0001, # 0.001*100000 = 100, ragionevole\n",
    "        # max_df = 0.7,\n",
    "        ngram_range = (gram_min, gram_max),\n",
    "        binary = False,\n",
    "        # vocabulary = my_dic\n",
    "    )  \n",
    "\n",
    "train_tf_idf = vectorizer.fit_transform(train.df['Clean_Review'])\n",
    "\n",
    "print(train_tf_idf.shape)\n",
    "\n",
    "      #-- FEATURE SELECTION\n",
    "\n",
    "select_percentile = SelectPercentile(chi2, percentile=10)\n",
    "train_tf_idf = select_percentile.fit_transform(train_tf_idf, train.df['Labels'])\n",
    "\n",
    "print(train_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uiwrjLyJ00S",
    "outputId": "99b258cd-599d-4eee-a4dd-f494df540069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            ***** KNN ****\n",
      "     Measure                Mean             StandError\n",
      "0  TrainTime  0.0501004695892334  5.531554973090335e-06\n",
      "1   TestTime  360.98127636909487     0.1527442466782814\n",
      "2         F1  0.6731040000000001  3.004069772824845e-05\n",
      "3   Accuracy   0.669575876158963  5.555106304403867e-05\n",
      "                                                            ***** Linear SVC ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime   2.6826063632965087  0.00037259812446662383\n",
      "1   TestTime  0.03076624870300293   3.893558038888187e-06\n",
      "2         F1   0.8942439999999999  1.0251493549722402e-05\n",
      "3   Accuracy   0.8948552432109123  1.0010236064449383e-05\n",
      "                                                            ***** Logistic ****\n",
      "     Measure                  Mean             StandError\n",
      "0  TrainTime     6.419427919387817   0.002759457574639326\n",
      "1   TestTime  0.029975175857543945  2.117509640714302e-06\n",
      "2         F1    0.8878199999999999  9.309607940187243e-06\n",
      "3   Accuracy    0.8882961667782983  7.850317949755712e-06\n",
      "                                                            ***** Stochastic Gradient Descent Classifier ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime    0.4898341178894043   3.410060856795713e-05\n",
      "1   TestTime  0.030513238906860352   6.697883517857536e-06\n",
      "2         F1              0.873268  1.0079746028546633e-05\n",
      "3   Accuracy    0.8734602921801999   8.035613492734419e-06\n",
      "                                                            ***** Multinomial Naive Bayes ****\n",
      "     Measure                 Mean              StandError\n",
      "0  TrainTime  0.07755799293518066   1.346755452338084e-05\n",
      "1   TestTime  0.03367781639099121  5.7554264748102955e-06\n",
      "2         F1             0.872132  1.1858687954407221e-05\n",
      "3   Accuracy   0.8734362732481136  1.1023213523338297e-05\n",
      "                                                            ***** Adaboost ****\n",
      "     Measure                Mean              StandError\n",
      "0  TrainTime    89.1681562423706   0.0060359236685354565\n",
      "1   TestTime    1.27187237739563   8.757898413575997e-05\n",
      "2         F1            0.821184  1.3910065420406899e-05\n",
      "3   Accuracy  0.8208625104329371  1.6525429574532303e-05\n",
      "                                                            ***** Bernullian Naive Bayes ****\n",
      "     Measure                  Mean              StandError\n",
      "0  TrainTime   0.10534796714782715  1.0197549395197785e-05\n",
      "1   TestTime  0.043253183364868164  1.1226907455690168e-05\n",
      "2         F1    0.8674799999999999   8.185059559954549e-06\n",
      "3   Accuracy    0.8711708897514111    7.48288897989758e-06\n",
      "CPU times: user 38min 20s, sys: 6.68 s, total: 38min 26s\n",
      "Wall time: 38min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = classification(train_tf_idf, train.df['Labels'], cv)\n",
    "\n",
    "my_class = ['KNN', 'LSVC', 'Logistic', 'SGD', 'MNB', 'ADAB', 'BNB']\n",
    "\n",
    "for c in my_class:\n",
    "  print(f\"                                                            ***** {decode(c)} ****\")\n",
    "  learn.select_model(c)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Classificazione(1,2)CVMore.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
