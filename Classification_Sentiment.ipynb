{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPERVISED SENTIMENT ANALYSIS\n",
    "\n",
    "Lo scopo di questo jupyter è quello di classificare le revisioni di Amazon attraverso delle tecniche principalmente utilizzate per i Social Media. Ci si aspetta che tali tecniche siano più sensibili nel riconoscere il sentimento rispetto alla classificazione pura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idXNuKcemVSF",
    "outputId": "a6f4e039-a8be-473c-eb9a-17c2108f81a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnIyX7rHmXUB",
    "outputId": "15b12430-1f69-4508-dc74-25097b108e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo1UQeIbmf3P",
    "outputId": "95ea5993-7e80-415d-8789-f09d0bbb868c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import string\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Le emoji e il controllo sulla lingua non servono (ci sono pochi documenti in spagnolo)\n",
    "# perché fineranno nella coda della distribuzione e saranno dimenticati.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words = stop_words + ['would'] + ['-PRON-'] \n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yNRJ4Kb_mwu7"
   },
   "outputs": [],
   "source": [
    "# NLP pipeline.\n",
    "# Check language: it's so slow.\n",
    "# if detect(doc) != 'en':\n",
    "# return []\n",
    "\n",
    "def pipe(doc):\n",
    "  doc = doc.lower()\n",
    "  # Drop digits. \n",
    "  doc = re.sub(r'\\d+', ' ', doc) \n",
    "  # Drop punctuation.\n",
    "  doc = re.sub('['+string.punctuation+']', ' ', doc) \n",
    "  # Drop newline.\n",
    "  doc = re.sub(r'\\n+', ' ', doc) \n",
    "  # Drop URL.\n",
    "  if 'www.' in doc or 'http:' in doc or 'https:' in doc or '.com' in doc:\n",
    "    doc = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", doc)\n",
    "  # Drop emoji.\n",
    "  # doc = demoji.replace(string = doc, repl = \" \")\n",
    "  # Drop extra spaces.\n",
    "  doc = re.sub(r'\\s\\s+', ' ', doc) \n",
    "  # Tpkenize and Lemmatization.\n",
    "  doc = nlp(doc)\n",
    "  doc = [token.lemma_ for token in doc]   \n",
    "  # Tokenize.\n",
    "  # doc = text_to_word_sequence(doc)\n",
    "  # Drop short words.\n",
    "  doc = [word for word in doc if len(word) > 2]\n",
    "  # Drop stop words.\n",
    "  doc = [word for word in doc if word not in stop_words]\n",
    "  return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IowrgiSWm231"
   },
   "outputs": [],
   "source": [
    "\n",
    "# NLP pipeline.\n",
    "class preprocessing:\n",
    "  # Initialize.\n",
    "  def __init__(self, path, name_df):\n",
    "    self.path = path\n",
    "    self.name_df = name_df\n",
    "\n",
    "  # Load data.\n",
    "  def loader(self):\n",
    "    print('IMPORT DATASET ' + self.name_df)\n",
    "    if os.path.isfile(self.path) == False: \n",
    "      print('Set not exists.')\n",
    "      raise SystemExit(\"Stop right there!\")\n",
    "    else:\n",
    "      with open(self.path, encoding=\"utf8\") as file:\n",
    "       self.df = file.readlines()\n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    " # Sampling.\n",
    "  def sampling(self, size):\n",
    "    print('SAMPLING ' + self.name_df)\n",
    "    random.seed = 20201230\n",
    "    self.df = random.sample(self.df, size)  \n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    "  # From list to data frame\n",
    "  def data_frame(self):\n",
    "    print('CREATE DATASET: REVIEWS - LABELS ' + self.name_df)\n",
    "    X = []\n",
    "    labels = []\n",
    "\n",
    "    for rev in self.df:\n",
    "      _, label, sent = re.split(r'__label__(\\d)', rev)\n",
    "      label = int(label[0]) -1\n",
    "      labels.append(label)\n",
    "      X.append(sent)\n",
    "\n",
    "    self.df = pd.DataFrame(list(zip(X, labels)), columns=['Review', 'Labels']) \n",
    "\n",
    "  # NLP pipeline.\n",
    "  def pipeline(self):\n",
    "    print('NLP pipeline ' + self.name_df)\n",
    "    t1 = time()\n",
    "    self.df[\"Clean_Review\"] = self.df[\"Review\"].apply(pipe)\n",
    "    t2 = time()\n",
    "    print(f\"Time: {t2-t1}\")\n",
    "\n",
    "  # Empty review,\n",
    "  def drop_empty_review(self):\n",
    "    print('DROP EMPTY REVIEW ' + self.name_df)\n",
    "    self.df.drop(self.df[self.df['Clean_Review'].map(len) == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHr4FzgCnZGg",
    "outputId": "7e5f1c7c-215a-4fc7-af63-79b1a4057302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT DATASET TRAIN\n",
      "Size: 3600000\n",
      "SAMPLING TRAIN\n",
      "Size: 250000\n",
      "CREATE DATASET: REVIEWS - LABELS TRAIN\n",
      "NLP pipeline TRAIN\n",
      "Time: 1432.0943808555603\n",
      "DROP EMPTY REVIEW TRAIN\n",
      "CPU times: user 23min 43s, sys: 5.89 s, total: 23min 49s\n",
      "Wall time: 24min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "        #-- IMPORT SET.\n",
    "\n",
    "train_path = 'drive/MyDrive/Text Mining/train.ft.txt'\n",
    "\n",
    "train = preprocessing(train_path, 'TRAIN')\n",
    "\n",
    "train.loader()\n",
    "\n",
    "\n",
    "      #-- SAMPLING.\n",
    "\n",
    "train_sample_size = 250000\n",
    "train.sampling(train_sample_size)\n",
    "\n",
    "      #-- CREATE A DATASET WITH REVIEW - LABEL.\n",
    "\n",
    "train.data_frame()\n",
    "\n",
    "      #-- PREPROCESSING.\n",
    "\n",
    "train.pipeline()\n",
    "\n",
    "train.drop_empty_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtIwxFyCm-ul"
   },
   "source": [
    "### ***SENTIMENT SUPERVISED ANALYSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pp_bNyPMm5Qo"
   },
   "outputs": [],
   "source": [
    "# Define a threshold to define positive, negative and neutral reviews.\n",
    "def assign_sent(value, thr):\n",
    "  # dataset doesn't contain neutral comments.\n",
    "  thr = thr\n",
    "  if -thr <= value <= thr:\n",
    "    # put this value to neutral reviews: they will be dropped.\n",
    "    value = -999\n",
    "  else: \n",
    "    if  value < 0:\n",
    "      value = 0\n",
    "    else:\n",
    "      value = 1\n",
    "  return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMoV71sDnE2J"
   },
   "source": [
    "#### ***AFFIN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTrOkGoenEGy",
    "outputId": "88dcbf0e-08e8-47e0-b539-e40301d6abcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
      "\r",
      "\u001b[K     |██████▎                         | 10kB 16.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 20kB 20.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 30kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 40kB 9.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 51kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53450 sha256=ce5347867d84584299149c965f1fd68a71c85e79ac3e4b3ecb7a67c982895dfb\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsoYqk-knHH1",
    "outputId": "b4a7d499-a531-4cdf-c927-6f4b9432a6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      "\n",
      " Labels           0       1\n",
      "Affin_Label               \n",
      "0            35884    3960\n",
      "1            45706  105980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.44      0.59     81590\n",
      "           1       0.70      0.96      0.81    109940\n",
      "\n",
      "    accuracy                           0.74    191530\n",
      "   macro avg       0.80      0.70      0.70    191530\n",
      "weighted avg       0.78      0.74      0.72    191530\n",
      "\n",
      "CPU times: user 11min 17s, sys: 193 ms, total: 11min 17s\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "def affin_exe(review):\n",
    "  # compute che score provided by Afinn for each review.\n",
    "  aff = afinn.score(review)\n",
    "# define the sentiment of the review.\n",
    "  aff = assign_sent(aff, 2)\n",
    "  return aff\n",
    "\n",
    "train.df['Affin_Label'] = train.df['Review'].apply(affin_exe)\n",
    "\n",
    "# Save the non neutral reviews.\n",
    "# I have to create an appo matrix! I will delete object of train.df\n",
    "train_appo = train.df\n",
    "train_appo = train_appo[train_appo['Affin_Label'] != -999]\n",
    "\n",
    "train_appo['Affin_Label'].value_counts()\n",
    "\n",
    "cm = pd.crosstab(train_appo.Affin_Label, train_appo.Labels)\n",
    "print(f\"\\n Confusion matrix: \\n\\n {cm}\")\n",
    "# risultato un po' pessimo.\n",
    "print(classification_report(train_appo.Labels, train_appo.Affin_Label))\n",
    "\n",
    "# Si osserva che l'algoritmo riesce a inferire bene i commenti positivi\n",
    "# ma non è molto performante per quelli negativi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkeCteyhnPqP"
   },
   "source": [
    "#### ***OPINION LEXICON***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAXhr-cKnKxN",
    "outputId": "914a0a0f-cfd4-423c-c977-baedc3b41df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "# Liste di termini positivi e negativi offerti. \n",
    "pos_list=set(opinion_lexicon.positive())\n",
    "neg_list=set(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTehRVM3njqY",
    "outputId": "35f2bfe4-c6b7-49cb-c017-f1f314c1ccc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      "\n",
      " Count_Sent      0      1\n",
      "Labels                  \n",
      "0           43344  32157\n",
      "1            5551  94753 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.89      0.70     48895\n",
      "           1       0.94      0.75      0.83    126910\n",
      "\n",
      "    accuracy                           0.79    175805\n",
      "   macro avg       0.76      0.82      0.77    175805\n",
      "weighted avg       0.84      0.79      0.80    175805\n",
      "\n",
      "CPU times: user 1.77 s, sys: 9.48 ms, total: 1.78 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# compute the score of each review on the basis of the word \n",
    "# of opinion lexicon whithin each of them.\n",
    "def sentiment_sum(sentence):\n",
    "  counter = 0\n",
    "  for word in sentence:\n",
    "    if word in pos_list:\n",
    "      counter += 1\n",
    "    elif word in neg_list:\n",
    "      counter -= 1\n",
    "\n",
    "  counter = assign_sent(counter, 1)\n",
    "  return counter\n",
    "\n",
    "train.df['Count_Sent'] = train.df['Clean_Review'].apply(sentiment_sum)\n",
    "\n",
    "train_appo = train.df\n",
    "train_appo = train_appo[train_appo['Count_Sent'] != -999]\n",
    "\n",
    "train_appo['Count_Sent'].value_counts()\n",
    "\n",
    "cm = pd.crosstab(train_appo.Labels, train_appo.Count_Sent)\n",
    "print(f\"\\n Confusion matrix: \\n\\n {cm}\", '\\n')\n",
    "\n",
    "# risultato un po' pessimo.\n",
    "print(classification_report(train_appo.Count_Sent, train_appo.Labels))\n",
    "# Anche qui non classifica bene i commenti negativi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_ej8B5enpGz"
   },
   "source": [
    "#### ***VADER***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaJrDLFWnoPF",
    "outputId": "a1323c02-8495-422f-b7c3-0fff27134643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 13.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 20kB 15.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 30kB 14.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 40kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 51kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 61kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 71kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 81kB 6.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 92kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 102kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 112kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 122kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    " !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsnx3Oqxnvzi",
    "outputId": "fe952aa1-886a-4437-93b3-53b9e6bdbee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion matrix: \n",
      "\n",
      " Vader_sent      0       1\n",
      "Labels                   \n",
      "0           59586   58298\n",
      "1            7298  115142, \n",
      "\n",
      " Accuracy: 72.70518133852633%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.51      0.64    117884\n",
      "           1       0.66      0.94      0.78    122440\n",
      "\n",
      "    accuracy                           0.73    240324\n",
      "   macro avg       0.78      0.72      0.71    240324\n",
      "weighted avg       0.78      0.73      0.71    240324\n",
      "\n",
      "CPU times: user 3min 31s, sys: 648 ms, total: 3min 31s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Define vader score.\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "train.df['Vader_sent'] = train.df['Review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Encode lab 0 or 1.\n",
    "train.df['Vader_sent'] = train.df['Vader_sent'].apply(lambda x: assign_sent(x, 0.1))\n",
    "\n",
    "train_appo = train.df\n",
    "train_appo = train_appo[train_appo['Vader_sent'] != -999]\n",
    "\n",
    "train_appo['Vader_sent'].value_counts()\n",
    "\n",
    "cm = pd.crosstab(train_appo.Labels, train_appo.Vader_sent)\n",
    "acc = np.sum(np.diag(cm)) / np.sum(cm.values)\n",
    "print(f\"\\n Confusion matrix: \\n\\n {cm}, \\n\\n Accuracy: {acc*100}%\")\n",
    "\n",
    "# risultato un po' pessimo.\n",
    "print(classification_report(train_appo.Labels, train_appo.Vader_sent))\n",
    "\n",
    "# Sbaglia nel classificare i commenti negativi e li scambia per positivi."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Classification- Sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
