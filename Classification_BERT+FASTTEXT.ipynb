{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION CON BERT E FASTTEXT\n",
    "\n",
    "Lo scopo di questo jupyter è quello di indagare le tecniche di classificazione attraverso delle reti neurali: bert e fasttext. In particolare, si vuole capire come queste strutture funzionano ed il livello di accuratezza raggiunti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sl-ZiMYipAgY",
    "outputId": "1f8e4d33-f90e-46ad-8124-40208359c511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qhqMPzoqsWk",
    "outputId": "20deced6-6c47-4e5c-9ac4-2b4938df4a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 38.0 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BQScScDFqzFQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import string\n",
    "import os.path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jutk8uXpq2hL"
   },
   "outputs": [],
   "source": [
    "# Preprocessing data for BERT algorithm.\n",
    "class preprocessing:\n",
    "  # Initialize.\n",
    "  def __init__(self, path, name_df):\n",
    "    self.path = path\n",
    "    self.name_df = name_df\n",
    "\n",
    "  # Load data.\n",
    "  def loader(self):\n",
    "    print('IMPORT DATASET ' + self.name_df)\n",
    "    if os.path.isfile(self.path) == False: \n",
    "      print('Set not exists.')\n",
    "      raise SystemExit(\"Stop right there!\")\n",
    "    else:\n",
    "      with open(self.path, encoding=\"utf8\") as file:\n",
    "       self.df = file.readlines()\n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    " # Sampling.\n",
    "  def sampling(self, size):\n",
    "    print('SAMPLING ' + self.name_df)\n",
    "    random.seed = 20201230\n",
    "    self.df = random.sample(self.df, size)  \n",
    "    print(f\"Size: {len(self.df)}\")\n",
    "\n",
    "  # From list to data frame\n",
    "  def data_frame(self):\n",
    "    print('CREATE DATASET: REVIEWS - LABELS ' + self.name_df)\n",
    "    X = []\n",
    "    labels = []\n",
    "\n",
    "    for rev in self.df:\n",
    "      _, label, sent = re.split(r'__label__(\\d)', rev)\n",
    "      label = int(label[0]) -1\n",
    "      labels.append(label)\n",
    "      X.append(sent)\n",
    "\n",
    "    self.df = pd.DataFrame(list(zip(X, labels)), columns=['Review', 'Labels']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rm7VD0E1q4MK",
    "outputId": "9fb6f39c-af7e-4639-ceaa-89b05e936c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT DATASET TRAIN\n",
      "Size: 3600000\n",
      "SAMPLING TRAIN\n",
      "Size: 250000\n",
      "CREATE DATASET: REVIEWS - LABELS TRAIN\n",
      "CPU times: user 2.6 s, sys: 2.23 s, total: 4.84 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "        #-- IMPORT SET.\n",
    "\n",
    "train_path = 'drive/MyDrive/Text Mining/train.ft.txt'\n",
    "\n",
    "train = preprocessing(train_path, 'TRAIN')\n",
    "\n",
    "train.loader()\n",
    "\n",
    "\n",
    "      #-- SAMPLING.\n",
    "\n",
    "train_sample_size = 250000\n",
    "train.sampling(train_sample_size)\n",
    "\n",
    "      #-- CREATE A DATASET WITH REVIEW - LABEL.\n",
    "\n",
    "train.data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxUoIJpkQQmW"
   },
   "source": [
    "### **BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYh-Wb5oq629",
    "outputId": "b5d053f9-2f7b-448b-b62b-358f52b54c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/23/6f5addc2ade7c6240e2c9169bd7a9506cea17b35c9f322104a60dd4ba7fd/ktrain-0.25.2.tar.gz (25.3MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3MB 90.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.22.2.post1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.1.5)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.17.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.7)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 59.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n",
      "Collecting cchardet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/e5/a0b9edd8664ea3b0d3270c451ebbf86655ed9fc4c3e4c45b9afae9c2e382/cchardet-2.1.7-cp36-cp36m-manylinux2010_x86_64.whl (263kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 69.1MB/s \n",
      "\u001b[?25hCollecting syntok\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n",
      "Collecting seqeval==0.0.19\n",
      "  Downloading https://files.pythonhosted.org/packages/93/e5/b7705156a77f742cfe4fc6f22d0c71591edb2d243328dff2f8fc0f933ab6/seqeval-0.0.19.tar.gz\n",
      "Collecting transformers<4.0,>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 60.2MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 48.9MB/s \n",
      "\u001b[?25hCollecting keras_bert>=0.86.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
      "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.5)\n",
      "Collecting whoosh\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 59.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->ktrain) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->ktrain) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (50.3.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->ktrain) (1.15.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from syntok->ktrain) (2019.12.20)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.19->ktrain) (2.4.3)\n",
      "Collecting tokenizers==0.9.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 62.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.0.12)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.12.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (0.8)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 74.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (4.41.1)\n",
      "Collecting keras-transformer>=0.38.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (2.10.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.0,>=3.1.0->ktrain) (7.1.2)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Building wheels for collected packages: ktrain, langdetect, syntok, seqeval, keras-bert, sacremoses, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ktrain: filename=ktrain-0.25.2-cp36-none-any.whl size=25276306 sha256=4759d9b40db9565b9cb84a2c382546e756966c26113d1f5df551872ec750258e\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/56/00/25444c352cc843e5c5daea0e9517a192878ae22c2c6b5f4573\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=a519aba4e4a2867991e624537cc4daa8b4bc5e11e95a7cb9e04ed98568c25f90\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20919 sha256=7880c25dc871793f9eb3e56b37c717867a73b7778b88362d0458bbc34a927a63\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.19-cp36-none-any.whl size=9920 sha256=59d8fb40a1646c663becd45e468b441f4d9e28f6c4b0fed6e85b1cb7bc9b6ee1\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/1f/bf/1198beceed805a2099060975f6281d1b01046dd279e19c97be\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34146 sha256=5b6ae922ed9433dd7223a2033e4c8a46c969e4a4a26342154e01c44098b2f217\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=a63b80e2c7bbb139d4c8e831028e4adfbc51dc889a6c2c61a804674243fe52a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=7e9e8c715d9a81d8cf912fb901e2252e69edf7103071e94e1d9862a4a6696f96\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=ad5d502135f709001c8c7723046e78dd9e7f205e9329578833d97d1d2c6b0cd7\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15610 sha256=1d1497e09f296619f3c1300d20edc5b1a2c314c28f7f20ed26a9a0f7fd49d84e\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5267 sha256=b1dcca2e535d03db091c8c6863cf5893123e8d552e3e040a8ccaf1822024cca5\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5625 sha256=80cdb2e3b83c243dd4b0f233fd0a0b220b80a6d9921d3461e1c891635ca15a13\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4560 sha256=7c0cf6c3bec7436335a676f6d48abfe7c7f06422b5e39afd6581d5f31499d22e\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=4825f272427c77bcb92870f878099248d7e6871d4f1ffa3f5b24985cf9c78417\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built ktrain langdetect syntok seqeval keras-bert sacremoses keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "\u001b[31mERROR: transformers 3.5.1 has requirement sentencepiece==0.1.91, but you'll have sentencepiece 0.1.94 which is incompatible.\u001b[0m\n",
      "Installing collected packages: langdetect, cchardet, syntok, seqeval, tokenizers, sentencepiece, sacremoses, transformers, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, whoosh, ktrain\n",
      "Successfully installed cchardet-2.1.7 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.25.2 langdetect-1.0.8 sacremoses-0.0.43 sentencepiece-0.1.94 seqeval-0.0.19 syntok-1.3.1 tokenizers-0.9.3 transformers-3.5.1 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PEFdQLj9rI-7"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gpRapuT8rJUl"
   },
   "outputs": [],
   "source": [
    "# Preprocess data.\n",
    "\n",
    "bert_df = train.df[['Review', 'Labels']].rename(columns = {'Labels': 'pos'})\n",
    "swap = {0:1, 1:0}\n",
    "bert_df['neg'] = bert_df['pos'].apply(lambda x: swap[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "8MnHvuC7rLNQ",
    "outputId": "a66ddd68-0c19-47c4-9640-79d7a0a70592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 1.94 s, total: 3min 22s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The function returns the train, test set and the preprocessing method of the text.\n",
    "(x_train, y_train), (x_val, y_val), preproc = text.texts_from_df(bert_df, \n",
    "                                                                   'Review', # name of column containing review text\n",
    "                                                                   label_columns=['neg', 'pos'],\n",
    "                                                                   maxlen=100, \n",
    "                                                                   max_features=100000,\n",
    "                                                                   preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgrolKoHrPIc",
    "outputId": "99ceb252-aa79-4e25-cf3e-b55a515519b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 100\n",
      "done.\n",
      "CPU times: user 8.89 s, sys: 1.83 s, total: 10.7 s\n",
      "Wall time: 5.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the BERT (Classifiation) model.\n",
    "model = text.text_classifier(name = 'bert',\n",
    "                            train_data = (x_train, y_train),\n",
    "                            preproc = preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNgQRzferQtz",
    "outputId": "286df22f-f756-489a-cf93-f2293339d2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 233 ms, sys: 427 ms, total: 660 ms\n",
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the BERT model.\n",
    "learner = ktrain.get_learner(model = model,\n",
    "                             train_data = (x_train, y_train),\n",
    "                             val_data = (x_val, y_val),\n",
    "                             batch_size = 12\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA9j-Zi5rSoq",
    "outputId": "222a051b-d042-4a1c-b130-67c48442102d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "18750/18750 [==============================] - 29607s 2s/step - loss: 0.1568 - accuracy: 0.9402 - val_loss: 0.1155 - val_accuracy: 0.9572\n",
      "CPU times: user 7d 15h 10min 23s, sys: 5h 58min 19s, total: 7d 21h 8min 42s\n",
      "Wall time: 8h 13min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faaed869ef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "learner.fit_onecycle(lr = 2e-5, # learning rate.\n",
    "                     epochs = 1 # it's very slow to perform.\n",
    "                    )\n",
    "\n",
    "# Ci ha messo 8 ore per finire.\n",
    "# Accuratezza di validazione del 95%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5E_f5FpH1mbX"
   },
   "source": [
    "### ***FASTTEXT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aDmAF4ur1l9V"
   },
   "outputs": [],
   "source": [
    "# DAL TERMINALE DI UBUNTU\n",
    "\n",
    "\n",
    "# Ho creato un file con 500000 di train e 55555 di test.\n",
    "\n",
    "# Per l'addestramento del modell ho cambiato un po' di parametri,\n",
    "# i migliori però si sono rivelati: \n",
    "# - learning rate: 0.1\n",
    "# - epoch 5\n",
    "# - wordNgrams: 1\n",
    "\n",
    "# ./fasttext supervised -input train_sample -output model -label __label__\n",
    "\n",
    "# Per le predizioni:\n",
    "# l'ultima parte serve per salvare le lebals predette.\n",
    "# ./fasttext predict model.bin test_sample > predicted_labels\n",
    "\n",
    "# Con:\n",
    "# ./fasttext test model.bin test_sample\n",
    "# ottengo solo la recall e la precision.\n",
    "# Import quindi il dataset per calcolarne l'accuratezza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IzLs2AG6MDK",
    "outputId": "6b1e30a4-dbcc-499b-8ea1-e9c7e5ee34dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy FastText: 0.905%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import decimal\n",
    "\n",
    "# Importo i valori predetti e forniti per calcolare l'accuratezza\n",
    "# dato che l'algoritmo di base fornisce solamente la recall e precision.\n",
    "with open('drive/MyDrive/Text Mining/predicted_labels', 'r') as file:\n",
    " y_pred = file.readlines()\n",
    "\n",
    "with open('drive/MyDrive/Text Mining/test_sample.txt', 'r') as file:\n",
    " y_true = file.readlines()\n",
    "\n",
    "y_pred = [int(re.split(r'__label__(\\d)', label)[1])-1 for label in y_pred]\n",
    "y_true = [int(re.split(r'__label__(\\d)', label)[1])-1 for label in y_true]\n",
    "\n",
    "# print(f\"Accuracy of FastText: {decimal.Decimal(accuracy_score(y_pred, y_true))}%\")\n",
    "\n",
    "print(\"Accuracy FastText: {0:.3f}%\".format(decimal.Decimal(accuracy_score(y_pred, y_true))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Classification- BERT+FASTTEXT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
